---
title: "[영상 처리] 다양한 공간적 필터링 기법"
date: 2023-05-16 00:00:00 +0900
categories: [Study, Image Processing]
tags: [dip]
math: true
---

- **필터링**(filtering)이란?
  
  - 영상을 포함한 신호에서 필요한 정보만 통과시키고 원치 않는 정보는 걸러 내는 작업
  
  - 신호 처리 분야의 *푸리에 변환*으로부터 시작됨. 푸리에 변환이란 *공간적인 신호를 주파수 공간으로 변환시키는 수학적 개념*. 공간적 영역의 영상을 주파수 공간으로 변환시키고, 주파수 공간에서 특정 주파수 성분을 제거하는 작업을 주파수 공간에서의 필터링이라고 함.

- **공간적 필터링**
  
  - 픽셀 값을 직접 사용하여 필터링을 수행하는 방식
  
  - 일반적으로 마스크를 사용하여 구현  
    *마스크 = 윈도우 = 템플릿 = 커널

![image1](https://github.com/ufolozie/ufolozie.github.io/assets/98166928/b1de75ec-0974-4f70-a481-f7afeee537e5){: width="70%" style="display: block; margin: auto;"}

3×3 크기의 마스크를 이용한 필터링 방법이다. f(x, y)는 입력 영상을, m(i, j)는 마스크를 의미한다.

$$
g(x,y)=\sum_{j=-1}^{1}\sum_{i=-1}^{1}m(i, j)f(x+i,y+j)
$$

$$
=m(-1,-1)f(x-1,y-1)+m(0,-1)f(x,y-1)+m(1,-1)f(x+1,y-1)
$$

$$
+m(-1,0)f(x-1,y)+m(0,0)f(x,y)+m(1,0)f(x+1,y)
$$

$$
+m(-1,1)f(x-1,y+1) + m(0,1)f(x,y+1) + m(1,1)f(x+1,y+1)
$$

입력 영상의 특정 좌표 (x, y)에 마스크 m의 중앙을 위치시키고, 마스크의 크기만큼 영상의 픽셀 값과 마스크의 값을 곱한 후 그 값들을 모두 더하여 결과 영상의 (x, y) 좌표 값으로 설정한다. 쉽게 말해 마스크 가운데를 타겟 값과 겹치고 주변 픽셀들을 대응하는 픽셀과 곱한 뒤, 최종적으로 더해서 가운데 값으로 치환하는 것이다. 여기서 마스크 m(i, j)의 값에 따라 이 마스크 연산이 어떤 역할을 하는지가 결정된다. 마스크 값의 형태에 따라 영상을 전반적으로 부드럽게 만들 수도 있고, 반대로 날카롭게 만들 수도 있다. 또한 영상에서 엣지 성분만 나타나도록 만들 수도 있다.

마스크의 모양과 크기는 필요에 따라 변경될 수 있다. 그러나 마스크의 크기가 커지거나 모양이 복잡해질수록 필터링 연산이 복잡해지거나 처리 속도가 증가할 수 있으므로 유의해야 한다. 실제 영상 처리에서는 3×3, 5×5 크기가 가장 많이 사용된다.

공간적 필터링을 구현하기 위해서는 기본적으로 영상 전체를 순회하는 작업이 필요하며, 픽셀 위에 마스크가 있다고 가정하고 마스크 연산을 수행해야 한다. 마스크 연산을 수행할 때, 각 픽셀에서 주변 픽셀들의 값을 참조하는 작업이 이루어지기 때문에 영상의 픽셀들을 2차원 배열 형태로 참조하는 방식이 편리하다. 따라서 GetPixels2D 멤버 함수를 주로 사용한다.

최외곽 픽셀들이란 0번째 행과 열, 그리고 w - 1번째 열과 h - 1번째 행에 위치한 픽셀들을 의미한다. 이때 실제 영상에서 존재하지 않는 픽셀 값을 참조하려고 하면 오류가 발생하게 되므로, 최외곽 픽셀에 대해서는 미리 규칙을 정해둔다.

- 최외곽 픽셀은 마스크 연산에서 제외한다.

- 최외곽 바깥에 가상의 픽셀이 있다고 가정한다(패딩(padding)).
  
  - 가상의 픽셀 값은 0 또는 주변 픽셀 값을 복사하여 사용한다.
  
  - 가상의 픽셀 값을 0으로 하는 것을 ‘제로 패딩’이라고 한다.

마스크 연산 시 주의할 점은, 원본 영상과 동일한 복사본을 만들어 픽셀 값을 참조해야 한다는 것이다.

<br>

## **영상 부드럽게 만들기**

**블러링**(bluring) 또는 **스무딩**(smoothing)이라고 한다. 영상이 부드럽다는 것은 픽셀 값이 급격하게 변화하지 않는 상태를 의미한다. 다양한 영상 처리 알고리즘에서 잡음을 제거하는 전처리 과정 용도로 사용된다.

<br>

### **평균 값 필터**

- 영상의 픽셀 값을 주변 픽셀 값들의 산술 평균으로 설정하는 필터

- 영상을 부드럽게 만들어주는 대표적인 필터

- 픽셀들 간의 그레이스케일 값 변화가 줄어들어 날카로운 엣지가 무뎌지는 효과

- 영상에 있는 잡음의 영향이 사라지는 효과

- 과도하게 사용할 경우 초점이 맞지 않는 것처럼 보일 수 있음

아래 그림은 3×3 크기와 5×5 크기의 평균 값 필터 마스크이다. 모든 마스크의 값이 1로 설정되어 있고, 필터 마스크 내에 들어가 있는 숫자들의 합으로 전체를 나눠주었다. 결과적으로 이 필터 마스크를 사용한 결과 영상의 픽셀 값은 입력 영상에서 주변 픽셀들의 평균 값을 가지게 되며, 결과 영상은 원본 영상에 비해 좀 더 부드러운 픽셀 분포를 가지게 된다. 평균 값 필터 마스크의 크기가 커질수록 더욱 부드러운 결과 영상이 생성되나, 그만큼 더 많은 연산량을 필요로 한다는 점에 주의한다.

![image2](https://github.com/ufolozie/ufolozie.github.io/assets/98166928/203ac49d-dbd6-44d6-b95d-ad18dfe8cc92){: width="70%" style="display: block; margin: auto;"}

‣ 평균 값 필터 구현 함수

```c++
void IppFilterMean(IppByteImage& imgSrc, IppByteImage& imgDst)
{
    int w = imgSrc.GetWidth();
    int h = imgSrc.GetHeight();

    imgDst = imgSrc; // IppByteImage 클래스의 대입 연산자에 의해 원본 영상 복사

    BYTE** pSrc = imgSrc.GetPixels2D();
    BYTE** pDst = imgSrc.GetPixels2D();

    int mask[3][3] = {
        { 1, 1, 1 },
        { 1, 1, 1 },
        { 1, 1, 1 }
    };

    // 영상 전체를 순회
    int i, j, m, n, sum;
    for (j = 1; j < h - 1; j++)
    for (i = 1; i < w - 1; i++)
    {
        // 마스크 배열 mask를 순회
        sum = 0;
        for (m = 0; m < 3; m++)
        for (n = 0; n < 3; n++)
        {
            sum += (pSrc[j - 1 + m][i - 1 + n] * mask[m][n]);
        }

        pDst[j][i] = static_cast<BYTE>(limit(sum / 9. + 0.5));
    }
}
```

<br>

### **가중 평균 값 필터**

- 주변 픽셀의 값을 많이 참조하기 때문에 원래 위치의 픽셀 정보가 상대적으로 감소하는 평균 값 필터의 단점을 보완하기 위한 방법

- 필터 마스크의 가운데 위치한 픽셀에 가중치를 더 주는 방법

- 마스크의 각 원소의 값이 동일하지 않고 중앙부의 값이 더 큰 값으로 구성된 마스크를 사용하는 필터

아래 그림은 가중 평균 값 필터 마스크의 모습이다. 일반 평균 값 필터와 달리 필터 중앙의 값이 크고, 중앙에서 멀어질수록 값이 작아지는 것을 볼 수 있다. 이는 마스크 중앙에 위치한 픽셀의 정보를 더욱 중요하게 취급하겠다는 의미이다. 마스크에 앞에 쓰여진 가중치 1/16과 1/256은 필터 마스크 값의 전체 합을 1로 만들어주기 위함이다. 필터 마스크 값의 합이 1보다 커질 경우, 필터링을 거친 결과 영상은 전반적으로 밝기 값이 증가되고, 1보다 작을 경우 밝기 값이 감소하게 되기 때문에 필터 마스크 값의 합을 1로 만들어주는 작업은 매우 중요하다.

![image3](https://github.com/ufolozie/ufolozie.github.io/assets/98166928/b1430a97-b607-4799-832d-36ac19a84f17){: width="70%" style="display: block; margin: auto;"}

*위와 같이 상하 좌우 대칭의 형태를 갖는 필터 마스크를 사용하는 필터를 등방성 필터라고 부른다. 일반 평균 값 필터도 등방성의 성질을 갖는다.

‣ 가중 평균 값 필터 구현 함수

```c++
void IppFilterWeightedMean(IppByteImage& imgSrc, IppByteImage& imgDst)
{
    int w = imgSrc.GetWidth();
    int h = imgSrc.GetHeight();

    imgDst = imgSrc;

    BYTE** pSrc = imgSrc.GetPixels2D();
    BYTE** pSrc = imgSrc.GetPixels2D();

    int mask[3][3] = {
        { 1, 2, 1 },
        { 2, 4, 2 },
        { 1, 2, 1 }
    };

    int i, j, m, n, sum;
    for (j = 1; j < h - 1; j++)
    for (i = 1; i < w - 1; i++)
    {
        sum = 0;
        for (m = 0; m < 3; m++)
        for (n = 0; n < 3; n++)
        {
            sum += (pSrc[j - 1 + m][i - 1 + n] * mask[m][n]);
        }

        pDst[j][i] = static_cast<BYTE>(limit(sum / 16. + 0.5));
    }
}
```

<br>

### **가우시안 필터**

- 2차원 가우시안 함수 값을 이용하여 마스크를 생성하고, 입력 영상과 마스크 연산을 수행하는 것

- 원래 가우시안 함수는 연속 함수이지만, 이산형의 마스크를 만들기 위해 x와 y 값이 정수인 위치에서만 가우시안 함수 값을 추출하여 마스크 생성

- 2차원 가우시안 함수를 1차원 함수의 곱으로 분할하여 입력 영상을 x 방향과 y 방향으로의 1차원 마스크 연산을 각각 수행함으로써 연산 속도 향상

즉, 입력 영상과 세로 방향의 1차원 가우시안 마스크와의 마스크 연산을 수행한 다음 그 결과 연산을 가지고 다시 가로 방향의 1차원 가우시안 마스크 연산을 수행한다는 것이다. 이처럼 세로와 가로 방향으로 각각 1차원 가우시안 마스크 연산을 수행하면 결국 2차원 가우시안 마스크 연산을 수행한 것과 동일한 결과를 생성하게 된다.

‣ 가우시안 필터 구현 함수

```c++
const float PI_F = 3.14159265358979323846f;


void IppFilterGaussian(IppByteImage& imgSrc, IppFloatImage& imgDst, float sigma)
{
    register int i, j, k, x;

    int w = imgSrc.GetWidth();
    int h = imgDst.GetHeight();

    imgDst.CreateImage(w, h);

    BYTE** pSrc = imgSrc.GetPixels2D();
    float** pDst = imgDst.GetPixels2D();

    /*
    * 1차원 가우시안 마스크 & 실수 연산을 위한 버퍼 이미지 생성
    */

    int dim = static_cast<int>(2 * 4 * sigma + 1.0); // 마스크 크기
    if (dim < 3) dim = 3; // sigma 값이 너무 작을 경우 최소 마스크 크기를 3으로 설정
    if (dim % 2 == 0) dim++;
    int dim2 = dim / 2;

    // 1차원 가우시안 마스크의 크기는 프로그램 동작 시 결정 -> 동적 메모리 할당하여 배열 생    
    IppFloatImage imgMask(dim, 1); // dim × 1 크기의 객체 생성
    float* pMask = imgMask.GetPixels();

    for (i = 0; i < dim; i++)
    {
        x = i - dim2;
        pMask[i] = exp(-(x * x) / (2 * sigma * sigma)) / (sqrt(2 * PI_F) * sigma);
    }

    IppFloatImage imgBuf(w, h);
    float** pBuf = imgBuf.GetPixels2D();

    /*
    * 세로 방향 마스크 연산
    */

    float sum1, sum2;
    for (i = 0; i < w; i++)
    for (j = 0; j < h; j++)
    {
        sum1 = sum2 = 0.f;

        for (k = 0; k < dim; k++)
        {
            x = k - dim2 + j;

            if (x >= 0 && x < h)
            {
                sum1 += pMask[k];
                sum2 += (pMask[k] * pSrc[x][i]);
            }
        }

        pBuf[j][i] = sum2 / sum1;
    }

    /*
    * 가로 방향 마스크 연산
    */

    for (j = 0; j < h; j++)
    for (i = 0; i < w; i++)
    {
        sum1 = sum2 = 0.f;

        for (k = 0; k < dim; k++)
        {
            x = k - dim2 + i;

            if (x >= 0 && x < w)
            {
                sum1 += pMask[k];
                sum2 += (pMask[k] * pSrc[j][i]);
            }
        }

        pDst[j][i] = sum2 / sum1;
    }
}
```

결과 영상은 표준 편차의 값이 커질수록 부드러워진다. 그러나 표준 편차의 값이 커지면 영상의 엣지 정보 또한 많이 뭉개지기 때문에 적절한 표준 편차의 값을 선택하여 사용해야 한다.

<br>

## **영상 날카롭게 만들기**

**샤프닝**(sharpening) 또는 **크리스프닝**(crispening)이라고 한다. 영상 내의 엣지 부분을 강조하여 영상을 더욱 선명한 느낌으로 만들어주는 영상 처리 기법이다.

<br>

### **언샤프 마스크 필터링**

- 영상을 날카롭게 만드는 방법 중 하나

- 날카롭지 않은 영상을 사용하기 때문에 언샤프 마스크 필터링이라고 함

언샤프 마스크 필터링에서는 다음과 같은 수식을 사용하여 영상의 엣지가 강조된 영상을 만들어 사용한다.

$$
g(x, y) = f(x, y) - \bar{f}(x,y)
$$

$$
h(x, y) = f(x, y) + g(x, y)
$$

$f(x, y)$는 입력 영상을, $\bar{f}(x, y)$는 입력 영상을 부드럽게 변환한 영상이다. 결과 영상 $g(x, y)$는 입력 영상에서 엣지 부분에 해당하는 픽셀에서만 큰 양수 또는 음수 값을 가지며, 평탄한 영역에서는 0에 가까운 값을 갖는다. 따라서 최종적으로 날카로운 부분만 강조한 영상을 만들기 위해 원래 영상에 g(x, y)를 더해주면 원하는 결과를 얻을 수 있다.

![image4](https://github.com/ufolozie/ufolozie.github.io/assets/98166928/370899ea-b4a9-4456-89e9-d1c04b5d9061)

사실 실제 구현에서는 앞선 빼기 연산을 이용하는 방법 대신 **영상의 이차 미분을 이용하는 방법을 많이 사용**한다. 이차 미분을 사용하면 여러 번의 연산을 수행하는 대신 하나의 마스크를 이용하는 형태로 날카로운 영상을 만들어낼 수 있기 때문이며, 결과 영상 자체도 더욱 날카로운 결과를 만들어내기 때문이다.

![image5](https://github.com/ufolozie/ufolozie.github.io/assets/98166928/cc08b9a7-a0be-4952-808f-15ae7baa7f91)

영상의 이차 미분은 일차 미분을 두 번 수행하여 구할 수 있다. 연속 함수가 아닌 이산 함수 f(x, y)에서 x 방향으로의 일차 미분은 다음의 수식으로 근사화할 수 있다.

$$
\frac{∂f}{∂x}=f(x+1,y)-f(x,y)
$$

함수 f를 x 방향으로 이차 편미분한 결과는 다음과 같다.

$$
\frac{∂^{2}f}{∂x^{2}}=[f(x+1,y)-f(x,y)]-[f(x,y)-f(x-1,y)]
$$

$$
=f(x+1,y)+f(x-1,y)-2f(x,y)
$$

만약 함수 f를 이차원 영상이라고 할 경우, 이 영상에 대한 이차 미분 함수는 x축과 y축에 대한 각각의 이차 미분을 수행하고, 각 방향에 대한 이차 미분 결과를 합하여 구할 수 있다.

$$
\nabla^2f=\frac{∂^2f}{∂x^2} + \frac{∂^2f}{∂y^2}
$$

$$
=[f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)]-4f(x,y)
$$

$∇^2$ 연산자가 이차 미분을 나타내는 연산자이며, 라플라시안(laplacian) 또는 델 스퀘어(del square)라고 읽는다. 위 수식을 마스크 형태로 만들면 아래와 같다.

![image6](https://github.com/ufolozie/ufolozie.github.io/assets/98166928/378328ec-42e7-4b16-a446-407907d90929){: width="70%" style="display: block; margin: auto;"}

왼쪽은 함수 f를 가로 및 세로 방향으로 미분 연산을 수행할 경우, 오른쪽은 가로, 세로, 양 대각선 방향으로 모두 미분 연산을 수행할 경우를 나타내는 마스크이다.

![image7](https://github.com/ufolozie/ufolozie.github.io/assets/98166928/a5f28759-42d4-4fc5-9102-e8202033e1ca)

결과 영상에서 회색으로 나타나는 부분은 라플라시안 필터 수행 결괏값이 0에 가까운 부분이고, 엣지 근방의 흰색 또는 검정색으로 표현된 픽셀은 라플라시안 결괏값이 큰 양수 또는 음수 값을 갖는 픽셀임을 의미한다.

라플라시안을 이용하여 영상을 날카롭게 만드는 방법을 다시 수식으로 정리하면 다음과 같다.

$$
h(x,y)=f(x,y)-∇^2f(x,y)
$$

$$
=f(x,y)-{[f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)]-4f(x,y)}
$$

$$
=5f(x,y) -f(x+1,y)-f(x-1,y)-f(x,y+1)-f(x,y-1)
$$

‣ 라플라시안 필터 구현 함수

```c++
void IppFilterLaplacian(IppByteImage& imgSrc, IppByteImage& imgDst)
{
    int w = imgSrc.GetWidth();
    int h = imgSrc.GetHeight();

    imgDst.CreateImage(w, h); // 결과 영상을 새로 생성하여 모든 픽셀 값을 0으로 초기화

    BYTE** pSrc = imgSrc.GetPixels2D();
    BYTE** pDst = imgDst.GetPixels2D();

    int i, j, sum;
    for (j = 1; j < h - 1; j++)
    for (i = 1; i < w - 1; i++)
    {
        sum = pSrc[j - 1][i] + pSrc[j][i - 1] + pSrc[j + 1][i] + pSrc[j][i + 1] - 4 * pSrc[j][i];

        pDst[j][i] = static_cast<BYTE>(limit(sum + 128);
    }
}
```

‣ 언샤프 마스크 필터 구현 함수

```c++
void IppFilterUnsharpMask(IppByteImage& imgSrc, IppByteImage& imgDst)
{
    int w = imgSrc.GetWidth();
    int h = imgSrc.GetHeight();

    imgDst = imgSrc;

    BYTE** pSrc = imgSrc.GetPixels2D();
    BYTE** pDst = imgDst.GetPixels2D();

    int i, j, sum;
    for (j = 1; j < h - 1; j++)
    for (i = 1; i < w - 1; i++)
    {
        sum = 5 * pSrc[j][i] - pSrc[j - 1][i] - pSrc[j][i - 1] - pSrc[j + 1][i] - pSrc[j][i + 1];

        pDst[j[i] = static_cast<BYTE>(limit(sum));
    }
}
```

위 두 함수는 마스크 배열을 따로 정의하여 사용하지 않았다. 대신 for 루프 안에서 4방향에 대한 픽셀 값을 직접 참조하여 결과 픽셀 값을 계산하였다.

라플라시안 필터 수행 시 최외곽 픽셀은 for 루프 연산에서 제외되기 때문에, 결과 영상의 최외곽 픽셀은 검정색으로 나타날 것이다.

<br>

### **하이부스트 필터**

- 언샤프 마스크 필터의 수정된 형태

- 입력 영상의 명암비를 전체적으로 높여주고 엣지를 강조함으로써 전체적으로 더욱 선명한 느낌이 드는 결과 영상 생성

다음과 같은 수식으로 정의된다.

$$
h(x,y)=α·f(x,y) + \nabla^2f(x,y)
$$

보통 α는 1보다 같거나 큰 실수로 정의하며, 입력 영상의 명암비를 다소 높여주면서 밝기를 전반적으로 밝게 만들어주는 역할을 한다. 만약 α가 1이면 앞서 설명한 언샤프 마스크 필터와 완전히 동일해진다.

‣ 하이부스트 필터 구현 함수

```c++
void IppFilterHighboost(IppByteImage& imgSrc, IppByteImage& imgDst, float alpha)
{
    int w = imgSrc.GetWidth();
    int h = imgSrc.GetHeight();

    imgDst = imgSrc;

    BYTE** pSrc = imgSrc.GetPixels2D();
    BYTE** pDst = imgDst.GetPixels2D();

    int i, j;
    float sum;
    for (j = 1; j < h - 1; j++)
    for (i = 1; i < w - 1; i++)
    {
        sum = (4 + alpha) * pSrc[j][i] - pSrc[j - 1][i] - pSrc[j][i - 1] - pSrc[j + 1][i] - pSrc[j][i + 1];

        pDst[j][i] = static_cast<BYTE>(limit(sum + 0.5f));
    }
}
```

<br>

## **잡음 생성**

영상에서 **잡음**(noise)이란 **영상의 픽셀 값에 추가되는 원치 않는 형태의 신호**를 의미한다. 예컨대 디지털 카메라로부터 영상을 획득하는 경우, 렌즈로부터 들어오는 광학 신호를 전기적 신호로 변환하는 센서에 잡음이 추가될 수 있다. 그러므로 카메라로부터 획득한 영상을 f(x, y)라고 하고 실제로 카메라 렌즈가 바라보는 화면 신호를 s(x, y)라고 할 경우, 다음과 같은 관계가 성립된다.

$$
f(x,y) = s(x,y)+n(x,y)
$$

n(x, y)는 잡음 신호를 나타낸다. 이러한 잡음은 항상 일정하지 않기 때문에 영상을 획득하는 시점에 따라 임의의 값으로 변할 수 있다. 즉, 카메라를 전혀 움직이지 않고 고정된 화면을 두 번 연속으로 촬영한다 하더라도, 획득된 두 영상은 완벽하게 동일한 픽셀 값을 가지지 않는다. 눈으로 보기에는 거의 동일한 밝기와 색상을 갖는 것처럼 보이지만 실제 픽셀 값을 살펴보면 아주 미세한 차이가 발생하는 것을 확인할 수 있다.

<br>

### **가우시안 잡음**

- 잡음으로 추가되는 값이 가우시안 함수 형태를 따르는 잡음

- 평균 값 필터, 가우시안 필터 등을 이용하여 어느 정도 그 효과를 감쇠시킬 수 있음. 그러나 엣지 같은 의미 있는 정보까지 함께 뭉개는 효과가 있기 때문에 주의해서 사용해야 함.

‣ 가우시안 임의 잡음 생성 함수

```c++
void IppNoiseGaussian(IppByteImage& imgSrc, IppByteImage& imgDst, int amount)
{
    int size = imgSrc.GetSize();

    imgDst = imgSrc;
    BYTE** pDst = imgDst.GetPixels();

    unsigned int seed = static_cast<unsigned int>(time(NULL));
    std::default_random_engine generator(seed);
    std::normal_distribution<double> distribution(0.0, 1.0);

    double rn;
    for (int i = 0; i < size; i++)
    {
        rn = distribution(generator) * 255 * amount / 100;
        pDst[i] = static_cast<BYTE>(limit(pDst[i] + rn));
    }
}
```

위 함수는 입력 영상 imgSrc에 대해 amount만큼의 가우시안 임의 잡음을 추가하고, 그 결과를 imgDst에 저장한다. amount 인자에는 0부터 100 사이의 정숫값을 전달하면 되고, 이는 각 픽셀마다 추가되는 잡음의 크기를 결정한다.

평균이 0이고, 표준 편차가 1인 가우시안 분포를 정상 분포라고 한다. 정상 분포를 갖는 난수를 발생시키기 위하여 유사 난수 발생기를 사용하는데, 프로그램 실행 시 항상 다른 값의 난수를 출력하기 위해 default_random_engine 객체 선언 시 임의의 숫자 값을 시드(seed) 값으로 부여한다. 그리고 time() 함수를 이용하여 현재 시스템 시간을 초단위로 얻어와 시드 값으로 사용하였다. 그러므로 위 코드가 1초 이내의 동일한 시간에 실행되지 않는 한, 항상 다른 형태의 정상 분포 난수가 발생하게 된다.

<br>

### **소금 & 후추 잡음**

- 잡음이 소금과 후추처럼 흰색 또는 검정색으로 구성

- 입력 영상의 임의의 좌표 픽셀 값을 0 또는 255로 만드는 형태의 잡음

- 주로 카메라 센서 자체의 에러 또는 광학 신호를 전기적 신호로 변환하는 과정에서 다양한 원인에 의해 발생

‣ 소금 & 후추 잡음 생성 함수

```c++
void IppNoiseSaltNPepper(IppByteImage& imgSrc, IppByteImage& imgDst, int amount)
{
    int size = imgSrc.GetSize();

    imgDst = imgSrc;
    BYTE** pDst = imgDst.GetPixels();

    unsigned int seed = static_cast<unsigned int>(time(0));
    std::default_random_engine generator(seed);
    std::uniform_int_distribution<int> distribution(0, size - 1);

    int num = size * amount / 100;
    for (int i = 0; i < num; i++)
    {
        pDst[distribution(generator)] = (i & 0x01) * 255;
    }
}
```

입력 영상 imgSrc에 amount 크기만큼의 소금 & 후추 잡음을 추가하고, 그 결과를 imgDst에 저장한다. amount는 소금 & 후추 잡음이 추가될 픽셀의 양을 제어하는 역할을 하며, 0부터 100 사이의 값을 전달하면 된다.

영상 내의 모든 픽셀에 대해 잡음을 추가하지 않고 임의의 픽셀에 대해서만 그 값을 0 또는 255로 설정하였다. 임의의 픽셀을 선택하기 위해 rand 함수를 이용하였고, std::uniform_int_distribution을 이용하여 소금 & 후추 잡음을 추가할 픽셀 위치를 구하였다.

size는 영상 전체 픽셀 개수, num은 잡음이 추가될 픽셀의 개수를 나타낸다.

입력 영상에서 잡음이 추가될 좌표는 distribution(generator) 코드를 사용하여 구한다. distribution(generator)은 0부터 (size - 1) 사이의 균일한 난수를 발생시킨다. 그리고 (i & 0x01) * 255를 픽셀 값으로 대입하였는데, i가 짝수이면 0이고 홀수이면 255가 대입된다.

<br>

## **잡음 제거를 위한 비선형 필터**

### **미디언 필터**

- 미디언(median) = 중간값

- 입력 영상에서 주변 픽셀들의 값들을 오름차순 또는 내림차순으로 정렬하여 그 중앙에 있는 값으로 픽셀 값을 대체

- 소금 & 후추 잡음을 효과적으로 제거하는 능력

- 마스크 값과 입력 픽셀 값을 곱하여 선형 합으로 계산하는 필터가 아니므로 비선형 공간적 필터링 기법으로 분류

‣ 미디언 필터 구현 함수

```c++
void IppFilterMedian(IppByteImage& imgSrc, IppByteImage& imgDst)
{
    int w = imgSrc.GetWidth();
    int h = imgSrc.GetHeight();

    imgDst = imgSrc;

    BYTE** pSrc = imgSrc.GetPixels2D();
    BYTE** pDst = imgDst.GetPixels2D();

    int i, j;
    BYTE m[9];
    for (j = 1; j < h - 1; j++)
    for (i = 1; i < w - 1; i++)
    {
        m[0] = pSrc[j - 1][i - 1]; m[1] = pSrc[j - 1][i]; m[2] = pSrc[j - 1][i + 1];
        m[3] = pSrc[j][i - 1]; m[4] = pSrc[j][i]; m[5] = pSrc[j][i + 1];
        m[6] = pSrc[j + 1][i - 1]; m[7] = pSrc[j + 1][i]; m[8] = pSrc[j + 1][i + 1];

        std::sort(m, m + 9);

        pDst[j][i] = m[4];
    }
}
```

픽셀 값 정렬을 위해서 sort 함수를 사용하였다. sort 함수는 정렬할 데이터의 첫 번째 원소의 주소와 마지막 원소의 바로 다음 주소를 인자로 받아 오름차순으로 정렬한다.

<br>

### **비등방성 확산 필터**

- 영상의 엣지 부분까지 부드럽게 만드는 등방성 필터의 단점을 보완한 필터

- 영상의 정보를 분석하여 각 방향의 필터링 정도를 다르게 결정

$$
I_{t} = div(c(x,y,t)\nabla i = c(x,y,t)\triangle I +\nabla c·\nabla I
$$

div는 발산 연산자, ∇와 ∆는 각각 그래디언트와 라플라시안 연산자이다(라플라시안 연산자 ∆는 $∇^2$의 형태로 쓰기도 한다). 함수 c(x, y, t)는 전달 계수라고 부른다.

위 수식을 디지털 영상 처리에 적용하기 위한 형태로 변경하면 다음과 같다.

$$
I_{i, j}^{t+1}=I_{i, j}^{t}+λ[c_{N}·\nabla _{N}I+c_{S}·\nabla _{S}I+c_{E}·\nabla _{E}I+c_{W}·\nabla _{W}I]
$$

영상 $I_{i, j}^{t}$는 시간이 t일 때 (i, j) 좌표의 픽셀 값을 의미한다. 그러므로 위 수식은 현재 (i, j) 위치의 픽셀 값이 네 방향에 대한 일차 미분에 해당하는 $∇_{N \sim W}I$, 그리고 $\ c_{N \sim W}$ 값을 이용하여 갱신됨을 의미한다. λ는 픽셀 값의 변화량을 결정짓는 상수이며, 0 ≤ λ ≤ 0.25를 만족해야 한다.

네 방향에 대한 영상의 그래디언트. 각 수식의 아래 첨자 N, S, E, W는 각각 북, 남, 동, 서 방향을 의미한다.

- $\nabla_{N}(I_{i, j})=I_{i,j-1}-I_{i, j}$

- $\nabla_{S}(I_{i, j})=I_{i,j+1}-I_{i, j}$

- $\nabla_{E}(I_{i, j})=I_{i+1,j}-I_{i, j}$

- $\nabla_{W}(I_{i, j})=I_{i-1,j}-I_{i, j}$

전달 계수 함수 $c_{N\sim W}$는 다음과 같이 구한다.

$$
c_{N \sim W} = g(||\nabla_{N\sim W}I||)= \frac{1}{1+(\frac{||\nabla_{N\sim W}I||}{K})^2}
$$

상수 K는 실험적으로 지정할 수 있는 상수이다.

‣ 비등방성 확산 필터 구현 함수

```c++
    void IppFilterDiffusion(IppByteImage& imgSrc, IppFloatImage& imgDst, float lambda, float k, int iter)
{
    int w = imgSrc.GetWidth();
    int h = imgSrc.GetHeight();

    IppFloatImage imgCpy;
    imgCpy.Convert(imgSrc);

    imgDst = imgSrc;

    float** pCpy = imgCpy.GetPixels2D();
    float** pDst = imgDst.GetPixels2D();

    // iter 횟수만큼 비등방성 확산 알고리즘 수행

    register int i, x, y;
    float gradn, grads, grade, gradw;
    float gcn, gcs, gce, gcw;
    float k2 = k * k;

    for (i = 0; i < iter; i++)
    {
        for (y = 1; y < h - 1; y++)
        for (x = 1; x < w - 1; x++)
        {
            gradn = pCpy[y - 1][x] - pCpy[y][x];
            grads = pCpy[y + 1][x] - pCpy[y][x];
            grade = pCpy[y][x - 1] - pCpy[y][x];
            gradw = pCpy[y][x + 1] - pCpy[y][x];

            gcn = gradn / (1.0f + gradn * gradn / k2);
            gcs = grads / (1.0f + grads * grads / k2);
            gce = grade / (1.0f + grade * grade / k2);
            gcw = gradw / (1.0f + gradw * gradw / k2);

            pDst[y][x] = pCpy[y][x] + lambda * (gcn + gcs + gce + gcw);
        }

        // 버퍼 복사
        if (i < iter - 1)
        {
            memcpy(imgCpy.GetPixels(), imgDst.GetPixels(), sizeof(float) * w * h);
        }
    }
}
```

입력 영상 imgSrc에 대해 비등방성 확산 필터링을 수행하고, 그 결과를 imgDst에 저장한다. 비등방성 필터링 구현 시 내부적으로 같은 동작을 여러 번 반복하는데, 그 반복 횟수를 다섯 번째 인자 iter로 받는다. 본 함수를 사용할 경우 전달해야 하는 인자의 값은 lambda = 0.25, k = 4를 유지하는 것이 바람직하며, iter 값은 4~30 정도가 적합하다.

<br>
